{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала изучение данных. Данные по разным больницам, количество записей:\n",
    "          Cleveland: 303\n",
    "          Hungarian: 294\n",
    "        Switzerland: 123\n",
    "      Long Beach VA: 200\n",
    "\n",
    "Разделяю набор на три части: обучающий, проверочный и оценочный набор.\n",
    "          Cleveland - обучающий\n",
    "          Hungarian - проверочный\n",
    "        Switzerland + Long Beach VA - оценочный\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland_file = open(\"cleveland.data\")\n",
    "hungarian_file = open(\"hungarian.data\")\n",
    "switzerland_file = open(\"switzerland.data\")\n",
    "longbeachva_file = open(\"long-beach-va.data\")\n",
    "\"\"\"\"\n",
    "learing_data\n",
    "dest_data\n",
    "rating_data\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_words(f):\n",
    "    all_data = []\n",
    "    indices = []\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        for word in line.split():\n",
    "            i += 1            \n",
    "            indices.append(word)\n",
    "            if word == \"name\":\n",
    "                if i == 76:\n",
    "                    person = []\n",
    "                    person.append(indices[3]) #3 age\n",
    "                    person.append(indices[4]) #4 sex\n",
    "                    person.append(indices[9]) #9 cp\n",
    "                    person.append(indices[10]) #10 trestbps\n",
    "                    person.append(indices[12]) #12 chol\n",
    "                    person.append(indices[16]) #16 fbs\n",
    "                    person.append(indices[19]) #19 restecg\n",
    "                    person.append(indices[32]) #32 thalach\n",
    "                    person.append(indices[38]) #38 exang\n",
    "                    person.append(indices[40]) #40 oldpeak\n",
    "                    person.append(indices[41]) #41 slope\n",
    "                    person.append(indices[44]) #44 ca\n",
    "                    person.append(indices[51]) #51 thal\n",
    "                    person.append(indices[58]) #58 num\n",
    "                \n",
    "                    all_data.append(person)\n",
    "                    #print(\"len\", i)\n",
    "                    i = 0\n",
    "                    indices = []\n",
    "                else:\n",
    "                    print(\"error definition\")\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error definition\n",
      "error definition\n",
      "error definition\n",
      "error definition\n",
      "error definition\n",
      "error definition\n",
      "error definition\n",
      "error definition\n",
      "error definition\n",
      "error definition\n",
      "error definition\n"
     ]
    }
   ],
   "source": [
    "cleveland_data = print_words(cleveland_file)\n",
    "hungarian_data = print_words(hungarian_file)\n",
    "switzerland_data = print_words(switzerland_file)\n",
    "longbeachva_data = print_words(longbeachva_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения -9 - отсутствующие значения. Заменю их на случайные числа от 0 до 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_range (0, 145)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-97d8a0ad9cec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m         hospital)\n\u001b[0;32m     72\u001b[0m \"\"\"\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mtrestbps_rang\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_min_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleveland_data_partially_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[0mcleveland_data_partially_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleveland_data_partially_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-81-97d8a0ad9cec>\u001b[0m in \u001b[0;36mfind_min_max\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mminv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mmaxv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmaxv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(10)\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def normalize_undefined_values(data):\n",
    "    new_data = []\n",
    "    for x in cleveland_data:\n",
    "        person = []\n",
    "        for y in x:\n",
    "            #print(\"y\", y)\n",
    "            if y == \"-9\":\n",
    "                person.append(random.uniform(0, 1))\n",
    "                #print(y)\n",
    "            else:\n",
    "                person.append(y)\n",
    "        new_data.append(person)\n",
    "    return new_data\n",
    "\n",
    "cleveland_data_undefined_normalized = normalize_undefined_values(cleveland_data)\n",
    "\n",
    "#print(\"cleveland_data\", cleveland_data)\n",
    "#print(\"cleveland_data_normalized\", cleveland_data_normalized)\n",
    "\n",
    "def normalize_index(data, idx, func):\n",
    "    new_data = []\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def find_min_max(data, index):\n",
    "    minv = 10000\n",
    "    maxv = -10000\n",
    "    for x in data[index]:\n",
    "        x = int(x)\n",
    "        if x > maxv:\n",
    "            maxv = x\n",
    "        elif x < minv:\n",
    "            minv = x\n",
    "    \n",
    "    return (minv, maxv)\n",
    "\n",
    "\"\"\"\n",
    "      3 age: age in years\n",
    "\"\"\"\n",
    "age_range = find_min_max(cleveland_data_undefined_normalized, 0)\n",
    "print(\"age_range\", age_range)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_undefined_normalized, 0, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "      4 sex: sex (1 = male; 0 = female)\n",
    "\"\"\"\n",
    "sex_range = (0, 1)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 1, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "      9 cp: chest pain type\n",
    "        -- Value 1: typical angina\n",
    "        -- Value 2: atypical angina\n",
    "        -- Value 3: non-anginal pain\n",
    "        -- Value 4: asymptomatic\n",
    "\"\"\"\n",
    "cp_range = (1, 4)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 2, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     10 trestbps: resting blood pressure (in mm Hg on admission to the \n",
    "        hospital)\n",
    "\"\"\"\n",
    "trestbps_rang = find_min_max(cleveland_data_partially_normalized, 3)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 3, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     12 chol: serum cholestoral in mg/dl\n",
    "\"\"\"\n",
    "chol = find_min_max(cleveland_data_partially_normalized)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 4, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "\"\"\"\n",
    "fbs_range = (0, 1)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 5, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     19 restecg: resting electrocardiographic results\n",
    "        -- Value 0: normal\n",
    "        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n",
    "                    elevation or depression of > 0.05 mV)\n",
    "        -- Value 2: showing probable or definite left ventricular hypertrophy\n",
    "                    by Estes' criteria\n",
    "\"\"\"\n",
    "restecg = (0, 2)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 6, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     32 thalach: maximum heart rate achieved\n",
    "\"\"\"\n",
    "thalach_range = find_min_max(cleveland_data_partially_normalized, 7)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 7, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     38 exang: exercise induced angina (1 = yes; 0 = no)\n",
    "\"\"\"\n",
    "exang_range = (0, 1)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 8, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     40 oldpeak = ST depression induced by exercise relative to rest\n",
    "\"\"\"\n",
    "oldpeak_range = find_min_max(cleveland_data_partially_normalized)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 9, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     41 slope: the slope of the peak exercise ST segment\n",
    "        -- Value 1: upsloping\n",
    "        -- Value 2: flat\n",
    "        -- Value 3: downsloping\n",
    "\"\"\"\n",
    "slope_range = (0, 3)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 10, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     44 ca: number of major vessels (0-3) colored by flourosopy\n",
    "\"\"\"\n",
    "ca_range = (0, 3)\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 11, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "\"\"\"\n",
    "thal_\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 12, lambda x: x)\n",
    "\n",
    "\"\"\"\n",
    "     58 num: diagnosis of heart disease (angiographic disease status)\n",
    "        -- Value 0: < 50% diameter narrowing\n",
    "        -- Value 1: > 50% diameter narrowing\n",
    "        (in any major vessel: attributes 59 through 68 are vessels)\n",
    "\"\"\"\n",
    "cleveland_data_partially_normalized = normalize_index(cleveland_data_partially_normalized, 13, lambda x: x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "np.random.seed(10)\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Required magic to display matplotlib plots in notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_act(x, der=False):\n",
    "    import numpy as np\n",
    "    \n",
    "    if (der==True) : #derivative of the sigmoid\n",
    "        f = x/(1-x)\n",
    "    else : # sigmoid\n",
    "        f = 1/(1+ np.exp(-x))\n",
    "    \n",
    "    return f\n",
    "\n",
    "# We may employ the Rectifier Linear Unit (ReLU)\n",
    "def ReLU_act(x, der=False):\n",
    "    import numpy as np\n",
    "    \n",
    "    if (der== True):\n",
    "        if x>0 :\n",
    "            f= 1\n",
    "        else :\n",
    "            f = 0\n",
    "    else :\n",
    "        if x>0:\n",
    "            f = x\n",
    "        else :\n",
    "            f = 0\n",
    "    return f\n",
    "\n",
    "# Now we are ready to define the perceptron; \n",
    "# it eats a np.array (that may be a list of features )\n",
    "def perceptron(X, act='Sigmoid'): \n",
    "    import numpy as np\n",
    "    \n",
    "    shapes = X.shape # Pick the number of (rows, columns)!\n",
    "    n= shapes[0]+shapes[1]\n",
    "    # Generating random weights and bias\n",
    "    w = 2*np.random.random(shapes) - 0.5 # We want w to be between -1 and 1\n",
    "    b = np.random.random(1)\n",
    "    \n",
    "    # Initialize the function\n",
    "    f = b[0]\n",
    "    for i in range(0, X.shape[0]-1) : # run over column elements\n",
    "        for j in range(0, X.shape[1]-1) : # run over rows elements\n",
    "            f += w[i, j]*X[i,j]/n\n",
    "    # Pass it to the activation function and return it as an output\n",
    "    if act == 'Sigmoid':\n",
    "        output = sigmoid_act(f)\n",
    "    else :\n",
    "        output = ReLU_act(f)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activator; we ask if we want the sigmoid or its derivative\n",
    "def sigmoid_act(x, der=False):\n",
    "    import numpy as np\n",
    "    \n",
    "    if (der==True) : #derivative of the sigmoid\n",
    "        f = 1/(1+ np.exp(- x))*(1-1/(1+ np.exp(- x)))\n",
    "    else : # sigmoid\n",
    "        f = 1/(1+ np.exp(- x))\n",
    "    \n",
    "    return f\n",
    "\n",
    "# We may employ the Rectifier Linear Unit (ReLU)\n",
    "def ReLU_act(x, der=False):\n",
    "    import numpy as np\n",
    "    \n",
    "    if (der == True): # the derivative of the ReLU is the Heaviside Theta\n",
    "        f = np.heaviside(x, 1)\n",
    "    else :\n",
    "        f = np.maximum(x, 0)\n",
    "    \n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 14\n",
    "hidden_nodes = 5\n",
    "output_nodes = 1\n",
    "\n",
    "# learning rate is 0.3\n",
    "learning_rate = 0.3\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
